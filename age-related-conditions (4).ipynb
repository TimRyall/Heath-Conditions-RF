{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**PACKAGES**\n> \nWe will first import the packages nessary to develop and run our models","metadata":{}},{"cell_type":"code","source":"# Basic data manipulation \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O \n\n# Data processing packages\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\n\n# Random Forest packages\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Boosting packages\nfrom sklearn.ensemble import GradientBoostingClassifier\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T04:56:55.366683Z","iopub.execute_input":"2023-05-21T04:56:55.368058Z","iopub.status.idle":"2023-05-21T04:56:55.374874Z","shell.execute_reply.started":"2023-05-21T04:56:55.368003Z","shell.execute_reply":"2023-05-21T04:56:55.373408Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTING DATA**\n> \nWe can now begin to import our data from the csv files","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"../input/icr-identify-age-related-conditions/\"\n\n# Read data in from files\n# Importing data set\ntrain_data = pd.read_csv(DATA_PATH + \"train.csv\") \nX = train_data.loc[:, train_data.columns != \"Class\"] # Data Inputs (Readings)\ny = train_data.loc[:, \"Class\"] # Data Outputs (Class labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:55.377387Z","iopub.execute_input":"2023-05-21T04:56:55.377742Z","iopub.status.idle":"2023-05-21T04:56:55.414849Z","shell.execute_reply.started":"2023-05-21T04:56:55.377713Z","shell.execute_reply":"2023-05-21T04:56:55.413707Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"**INITAL OBSERVATIONS**\n\nWe can look at the data to check what the data types and format of the data is. ","metadata":{}},{"cell_type":"code","source":"print(X.head()) \n# All data other than Id and EJ is numerical\n\nprint(f\"Null values in X: {X.isnull().sum().sum()}\")\n# There are a few null values which we will have to check out\nprint(f\"Null values in y: {y.isnull().sum()}\")\n# No null values in our lables which is good","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:55.416753Z","iopub.execute_input":"2023-05-21T04:56:55.417066Z","iopub.status.idle":"2023-05-21T04:56:55.435841Z","shell.execute_reply.started":"2023-05-21T04:56:55.417038Z","shell.execute_reply":"2023-05-21T04:56:55.434924Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"             Id        AB          AF          AH         AM        AR  \\\n0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n\n         AX        AY         AZ          BC  ...         FI        FL  \\\n0  0.699861  0.025578   9.812214    5.555634  ...   3.583450  7.298162   \n1  3.632190  0.025578  13.517790    1.229900  ...  10.358927  0.173229   \n2  6.732840  0.025578  12.824570    1.229900  ...  11.626917  7.709560   \n3  3.685344  0.025578  11.053708    1.229900  ...  14.852022  6.122162   \n4  3.942255  0.054810   3.396778  102.151980  ...  13.666727  8.153058   \n\n         FR        FS         GB          GE            GF         GH  \\\n0   1.73855  0.094822  11.339138   72.611063   2003.810319  22.136229   \n1   0.49706  0.568932   9.292698   72.611063  27981.562750  29.135430   \n2   0.97556  1.198821  37.077772   88.609437  13676.957810  28.022851   \n3   0.49706  0.284466  18.529584   82.416803   2094.262452  39.948656   \n4  48.50134  0.121914  16.408728  146.109943   8524.370502  45.381316   \n\n          GI         GL  \n0  69.834944   0.120343  \n1  32.131996  21.978000  \n2  35.192676   0.196941  \n3  90.493248   0.155829  \n4  36.262628   0.096614  \n\n[5 rows x 57 columns]\nNull values in X: 131\nNull values in y: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**PRE-PROCESSING DATA**\n> \nWe will first remove the ID column as that will not help us in any of our predictions as it is not related to the task\n\nWe will next imput the null values with the mean of that column\n","metadata":{}},{"cell_type":"code","source":"def process_data(data):\n    # Drop ID column\n    data = data.drop(\"Id\", axis=1)\n\n    # We can observe that EJ is catagorical but only takes two values\n    # A or B so we will set WLOG A to 1 and B to 0\n    #print(data[\"EJ\"].head())\n    data[\"EJ\"] = data[\"EJ\"].map({'A': 1, 'B': 0})\n    #print(data[\"EJ\"].head())\n\n    # Imput Null values with mean\n    data = data.fillna(data.mean(numeric_only=True))\n    #print(f\"Null values in X: {data.isnull().sum().sum()}\")\n    \n    return data\n\nX = process_data(X)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:55.438133Z","iopub.execute_input":"2023-05-21T04:56:55.438482Z","iopub.status.idle":"2023-05-21T04:56:55.470778Z","shell.execute_reply.started":"2023-05-21T04:56:55.438451Z","shell.execute_reply":"2023-05-21T04:56:55.469693Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN TEST SPLIT**\n\nWe will split the data in a training set and a hold out set for future validation","metadata":{}},{"cell_type":"code","source":"# split the data into a training and hold out set\nX_train, X_ho, y_train, y_ho = train_test_split(X, y, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:55.472339Z","iopub.execute_input":"2023-05-21T04:56:55.472687Z","iopub.status.idle":"2023-05-21T04:56:55.480047Z","shell.execute_reply.started":"2023-05-21T04:56:55.472656Z","shell.execute_reply":"2023-05-21T04:56:55.479224Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**CREATE RANDOM FOREST MODEL**\n\nWe will create simple random forest model to predict the data then compare our predictions with the hold out data set","metadata":{}},{"cell_type":"code","source":"# Construct the model\nmodel = RandomForestClassifier(n_estimators=300)  \nmodel.fit(X_train, y_train)\n\ny_pred_probs = model.predict_proba(X_ho)\ny_pred = np.argmax(y_pred_probs,axis = 1)\n\naccuracy = accuracy_score(y_ho, y_pred)\nprint(\"Accuracy against Hold Out set:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:55.481440Z","iopub.execute_input":"2023-05-21T04:56:55.482267Z","iopub.status.idle":"2023-05-21T04:56:56.702921Z","shell.execute_reply.started":"2023-05-21T04:56:55.482236Z","shell.execute_reply":"2023-05-21T04:56:56.701645Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy against Hold Out set: 0.9086021505376344\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**CREATE GRADIENT BOOST MODEL**\n\nWe will create a simple boosting model","metadata":{}},{"cell_type":"code","source":"# Construct the model\nmodel = GradientBoostingClassifier(n_estimators=300)  \nmodel.fit(X_train, y_train)\n\ny_pred_probs = model.predict_proba(X_ho)\ny_pred = np.argmax(y_pred_probs,axis = 1)\n\naccuracy = accuracy_score(y_ho, y_pred)\nprint(\"Accuracy against Hold Out set:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:56.704685Z","iopub.execute_input":"2023-05-21T04:56:56.705748Z","iopub.status.idle":"2023-05-21T04:56:58.838660Z","shell.execute_reply.started":"2023-05-21T04:56:56.705711Z","shell.execute_reply":"2023-05-21T04:56:58.836862Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Accuracy against Hold Out set: 0.8924731182795699\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**K FOLD CROSS VALIDATION**\n\nWe will do the same as we just did, however will apply futher testing to see which model will preform the best overall not just on the given split","metadata":{}},{"cell_type":"code","source":"# Import k fold cross validation modules\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nk = 10  # Number of folds\nkfold = KFold(n_splits=k, shuffle=True)  # Create KFold object\n\n# Test gradient boosting model\nmodel = GradientBoostingClassifier(n_estimators=300)  \nscores = cross_val_score(model, X, y, cv=kfold)\nprint(\"Accuracy with Boositing:\", scores.mean())\n\n# Test gradient boosting model\nmodel = RandomForestClassifier(n_estimators=300)  \nscores = cross_val_score(model, X, y, cv=kfold)\nprint(\"Accuracy with Random Forests:\", scores.mean())","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:56:58.840443Z","iopub.execute_input":"2023-05-21T04:56:58.840964Z","iopub.status.idle":"2023-05-21T04:57:38.332816Z","shell.execute_reply.started":"2023-05-21T04:56:58.840914Z","shell.execute_reply":"2023-05-21T04:57:38.331840Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Accuracy with Boositing: 0.9352987837123216\nAccuracy with Random Forests: 0.923823373876256\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**REFINING RANDOM FORESTS**\n\nWe see that random forests are our best model so we will refine the hyper parameters, namly the depth of tree\n","metadata":{}},{"cell_type":"code","source":"def best_rf_model():\n    depths = range(8, 18)\n    max_score = 0\n    for depth in depths:\n        model = RandomForestClassifier(n_estimators=300, max_depth = depth)  \n        scores = cross_val_score(model, X, y, cv=kfold)\n\n        # If found new best\n        if scores.mean() > max_score:\n            max_score = scores.mean()\n            best_depth = depth\n            print(f\"NEW Best Depth: {best_depth}, with Accuracy: {max_score}\")\n\n    print(f\"FINAL Best Depth: {best_depth}, with Accuracy: {max_score}\")\n    return RandomForestClassifier(n_estimators=1000, max_depth = best_depth)  ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:57:38.334642Z","iopub.execute_input":"2023-05-21T04:57:38.335048Z","iopub.status.idle":"2023-05-21T04:57:38.344258Z","shell.execute_reply.started":"2023-05-21T04:57:38.335013Z","shell.execute_reply":"2023-05-21T04:57:38.342889Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"**PREDICT TEST DATA**\n\nWe will now predict the unknown test data with this model","metadata":{}},{"cell_type":"code","source":"# Find best model to use\nmodel = best_rf_model()\nmodel.fit(X,y)\n\n# Import the data to predict\nX_test = pd.read_csv(DATA_PATH + \"test.csv\")\n\nids = X_test.loc[:, \"Id\"]\n# Do data processing\nX_test = process_data(X_test)\n\n# predict results\ny_test_probs = model.predict_proba(X_test)\nprint(y_test_probs)\n\nsubmissions = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n# We will change the Sample Submission value\nsubmissions[['class_0', 'class_1']] = y_test_probs\n\nsubmissions.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T04:57:38.348267Z","iopub.execute_input":"2023-05-21T04:57:38.348730Z","iopub.status.idle":"2023-05-21T04:59:56.196944Z","shell.execute_reply.started":"2023-05-21T04:57:38.348691Z","shell.execute_reply":"2023-05-21T04:59:56.195486Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"NEW Best Depth: 8, with Accuracy: 0.9142252776308831\nNEW Best Depth: 9, with Accuracy: 0.9204918032786885\nNEW Best Depth: 12, with Accuracy: 0.9286620835536754\nFINAL Best Depth: 12, with Accuracy: 0.9286620835536754\n[[0.523 0.477]\n [0.523 0.477]\n [0.523 0.477]\n [0.523 0.477]\n [0.523 0.477]]\n","output_type":"stream"}]}]}