{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**ACCOUNTING FOR META DATA**\n\nWe will now account for the second data file containing more infomation on what condition each patient has","metadata":{}},{"cell_type":"markdown","source":"**PACKAGES**\n> \nWe will first import the packages nessary to develop and run our models","metadata":{}},{"cell_type":"code","source":"# Basic data manipulation \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O \n\n# Data processing packages\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Random Forest packages\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss, make_scorer\n\n# Boosting packages\nfrom sklearn.ensemble import GradientBoostingClassifier\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-11T08:12:28.563908Z","iopub.execute_input":"2023-06-11T08:12:28.564279Z","iopub.status.idle":"2023-06-11T08:12:28.570303Z","shell.execute_reply.started":"2023-06-11T08:12:28.564239Z","shell.execute_reply":"2023-06-11T08:12:28.568687Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTING DATA**\n> \nWe can now begin to import our data from the csv files","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"../input/icr-identify-age-related-conditions/\"\n\n# Read data in from files\n# Importing data set\ninit_data = pd.read_csv(DATA_PATH + \"train.csv\") \nextra_data = pd.read_csv(DATA_PATH + \"greeks.csv\") \ntrain_data = pd.merge(init_data, extra_data, on='Id')\n\n# Data Inputs (Readings)\nX = train_data.drop([\"Class\", \"Alpha\", \"Epsilon\"], axis=1)\ny = train_data.loc[:, [\"Class\", \"Alpha\"]] # Data Outputs (Class labels)\n\nprint(X.head())","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.572383Z","iopub.execute_input":"2023-06-11T08:12:28.572755Z","iopub.status.idle":"2023-06-11T08:12:28.617203Z","shell.execute_reply.started":"2023-06-11T08:12:28.572716Z","shell.execute_reply":"2023-06-11T08:12:28.616261Z"},"trusted":true},"execution_count":298,"outputs":[{"name":"stdout","text":"             Id        AB          AF          AH         AM        AR  \\\n0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n\n         AX        AY         AZ          BC  ...        FS         GB  \\\n0  0.699861  0.025578   9.812214    5.555634  ...  0.094822  11.339138   \n1  3.632190  0.025578  13.517790    1.229900  ...  0.568932   9.292698   \n2  6.732840  0.025578  12.824570    1.229900  ...  1.198821  37.077772   \n3  3.685344  0.025578  11.053708    1.229900  ...  0.284466  18.529584   \n4  3.942255  0.054810   3.396778  102.151980  ...  0.121914  16.408728   \n\n           GE            GF         GH         GI         GL  Beta  Gamma  \\\n0   72.611063   2003.810319  22.136229  69.834944   0.120343     C      G   \n1   72.611063  27981.562750  29.135430  32.131996  21.978000     C      M   \n2   88.609437  13676.957810  28.022851  35.192676   0.196941     C      M   \n3   82.416803   2094.262452  39.948656  90.493248   0.155829     C      M   \n4  146.109943   8524.370502  45.381316  36.262628   0.096614     B      F   \n\n   Delta  \n0      D  \n1      B  \n2      B  \n3      B  \n4      B  \n\n[5 rows x 60 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**ONE HOT ENCODING**\n\nWe need to change the alpha \"type of positive class\" column to one hot encoding, since this is currently catagorical","metadata":{}},{"cell_type":"code","source":"# Change the main class column to now represent a one hot encoding of\n# the \"negative\" class\ny[\"Class\"] = y[\"Class\"].map({0: 1, 1: 0})\n\ndef one_hot_encode(col: str, data):\n    # create the cols, one for each class of the catagorical variable\n    one_hot_encoded = pd.get_dummies(data[col], prefix=col, prefix_sep='_')\n    \n    # Concatenate the one-hot encoded columns with the original DataFrame\n    data = pd.concat([data, one_hot_encoded], axis=1)\n    \n    # Drop the old column\n    data = data.drop(col, axis=1)\n    return data\n\n# one hot encode the classes in the output\ny = one_hot_encode(\"Alpha\", y)\n# drop Alpha_A since it is a the same as the neg column\ny = y.drop(\"Alpha_A\", axis=1)\ny = y.rename(columns={\"Class\":0, \"Alpha_B\":1, \"Alpha_D\":2, \"Alpha_G\":3,})\n\ny = y.idxmax(axis=1)\n\n\n# one hot encode the catagoral vars in X\nX = X.drop([\"Beta\", \"Gamma\", \"Delta\"], axis =1)\n#encoder = OneHotEncoder(handle_unknown='ignore')\n#encoder.fit(X.loc[:, [\"Beta\", \"Gamma\", \"Delta\"]])\n#X = pd.DataFrame(encoder.transform(X.loc[:, [\"Beta\", \"Gamma\", \"Delta\"]]).toarray())\n\nprint(X.head())","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.619096Z","iopub.execute_input":"2023-06-11T08:12:28.619620Z","iopub.status.idle":"2023-06-11T08:12:28.647127Z","shell.execute_reply.started":"2023-06-11T08:12:28.619589Z","shell.execute_reply":"2023-06-11T08:12:28.645443Z"},"trusted":true},"execution_count":299,"outputs":[{"name":"stdout","text":"             Id        AB          AF          AH         AM        AR  \\\n0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n\n         AX        AY         AZ          BC  ...         FI        FL  \\\n0  0.699861  0.025578   9.812214    5.555634  ...   3.583450  7.298162   \n1  3.632190  0.025578  13.517790    1.229900  ...  10.358927  0.173229   \n2  6.732840  0.025578  12.824570    1.229900  ...  11.626917  7.709560   \n3  3.685344  0.025578  11.053708    1.229900  ...  14.852022  6.122162   \n4  3.942255  0.054810   3.396778  102.151980  ...  13.666727  8.153058   \n\n         FR        FS         GB          GE            GF         GH  \\\n0   1.73855  0.094822  11.339138   72.611063   2003.810319  22.136229   \n1   0.49706  0.568932   9.292698   72.611063  27981.562750  29.135430   \n2   0.97556  1.198821  37.077772   88.609437  13676.957810  28.022851   \n3   0.49706  0.284466  18.529584   82.416803   2094.262452  39.948656   \n4  48.50134  0.121914  16.408728  146.109943   8524.370502  45.381316   \n\n          GI         GL  \n0  69.834944   0.120343  \n1  32.131996  21.978000  \n2  35.192676   0.196941  \n3  90.493248   0.155829  \n4  36.262628   0.096614  \n\n[5 rows x 57 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**INITAL OBSERVATIONS**\n\nWe can look at the data to check what the data types and format of the data is. ","metadata":{}},{"cell_type":"code","source":"print(X.head()) \nprint(y.head())\n# All data other than Id and EJ is numerical\n\nprint(f\"Null values in X: {X.isnull().sum().sum()}\")\n# There are a few null values which we will have to check out\nprint(f\"Null values in y: {y.isnull().sum().sum()}\")\n# No null values in our lables which is good","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.648638Z","iopub.execute_input":"2023-06-11T08:12:28.649070Z","iopub.status.idle":"2023-06-11T08:12:28.681647Z","shell.execute_reply.started":"2023-06-11T08:12:28.649040Z","shell.execute_reply":"2023-06-11T08:12:28.680413Z"},"trusted":true},"execution_count":300,"outputs":[{"name":"stdout","text":"             Id        AB          AF          AH         AM        AR  \\\n0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n\n         AX        AY         AZ          BC  ...         FI        FL  \\\n0  0.699861  0.025578   9.812214    5.555634  ...   3.583450  7.298162   \n1  3.632190  0.025578  13.517790    1.229900  ...  10.358927  0.173229   \n2  6.732840  0.025578  12.824570    1.229900  ...  11.626917  7.709560   \n3  3.685344  0.025578  11.053708    1.229900  ...  14.852022  6.122162   \n4  3.942255  0.054810   3.396778  102.151980  ...  13.666727  8.153058   \n\n         FR        FS         GB          GE            GF         GH  \\\n0   1.73855  0.094822  11.339138   72.611063   2003.810319  22.136229   \n1   0.49706  0.568932   9.292698   72.611063  27981.562750  29.135430   \n2   0.97556  1.198821  37.077772   88.609437  13676.957810  28.022851   \n3   0.49706  0.284466  18.529584   82.416803   2094.262452  39.948656   \n4  48.50134  0.121914  16.408728  146.109943   8524.370502  45.381316   \n\n          GI         GL  \n0  69.834944   0.120343  \n1  32.131996  21.978000  \n2  35.192676   0.196941  \n3  90.493248   0.155829  \n4  36.262628   0.096614  \n\n[5 rows x 57 columns]\n0    1\n1    0\n2    0\n3    0\n4    2\ndtype: int64\nNull values in X: 131\nNull values in y: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**PRE-PROCESSING DATA**\n> \nWe will first remove the ID column as that will not help us in any of our predictions as it is not related to the task\n\nWe will next imput the null values with the mean of that column\n","metadata":{}},{"cell_type":"code","source":"def process_data(data):\n    # Drop ID column\n    data = data.drop(\"Id\", axis=1)\n\n    # We can observe that EJ is catagorical but only takes two values\n    # A or B so we will set WLOG A to 1 and B to 0\n    #print(data[\"EJ\"].head())\n    data[\"EJ\"] = data[\"EJ\"].map({'A': 1, 'B': 0})\n    #print(data[\"EJ\"].head())\n\n    # Imput Null values with mean\n    data = data.fillna(data.mean(numeric_only=True))\n    #print(f\"Null values in X: {data.isnull().sum().sum()}\")\n    \n    return data\n\nX = process_data(X)\n\n\n## since testing data doesnt contain the meta data:\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.684383Z","iopub.execute_input":"2023-06-11T08:12:28.686200Z","iopub.status.idle":"2023-06-11T08:12:28.711341Z","shell.execute_reply.started":"2023-06-11T08:12:28.686161Z","shell.execute_reply":"2023-06-11T08:12:28.710245Z"},"trusted":true},"execution_count":301,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN TEST SPLIT**\n\nWe will split the data in a training set and a hold out set for future validation","metadata":{}},{"cell_type":"code","source":"# split the data into a training and hold out set\nX_train, X_ho, y_train, y_ho = train_test_split(X, y, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.712239Z","iopub.execute_input":"2023-06-11T08:12:28.712535Z","iopub.status.idle":"2023-06-11T08:12:28.719872Z","shell.execute_reply.started":"2023-06-11T08:12:28.712501Z","shell.execute_reply":"2023-06-11T08:12:28.718941Z"},"trusted":true},"execution_count":302,"outputs":[]},{"cell_type":"markdown","source":"**CREATE RANDOM FOREST MODEL**\n\nWe will create simple random forest model to predict the data then compare our predictions with the hold out data set","metadata":{}},{"cell_type":"code","source":"# Construct the model\nmodel = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", criterion=\"log_loss\")  \nmodel.fit(X_train, y_train)\n\ny_pred_probs = model.predict_proba(X_ho)\n\n#y_pred = np.argmax(y_pred_probs,axis = 1)\n#print(y_pred_probs[:5])\n\ndef conv_to_2_class(y_p_probs):\n    y_fin = [[0, 0] for _ in range(len(y_p_probs))]\n    for i, probs in enumerate(y_p_probs):\n        y_fin[i][0] = probs[0]\n        y_fin[i][1] = 1 - probs[0]\n    \n    return y_fin\ny_final = conv_to_2_class(y_pred_probs)\ny_pred = np.argmax(y_final, axis=1)\n\nprint(y_final[:5])\n#print(y_pred[:5])\n\ny_ho = y_ho.replace({2: 1, 3: 1})\nprint(y_ho)\n\naccuracy = accuracy_score(y_ho, y_pred)\nprint(\"Accuracy against Hold Out set:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:28.721125Z","iopub.execute_input":"2023-06-11T08:12:28.722177Z","iopub.status.idle":"2023-06-11T08:12:29.015717Z","shell.execute_reply.started":"2023-06-11T08:12:28.722143Z","shell.execute_reply":"2023-06-11T08:12:29.014639Z"},"trusted":true},"execution_count":303,"outputs":[{"name":"stdout","text":"[[0.94, 0.06000000000000005], [0.76, 0.24], [0.91, 0.08999999999999997], [0.98, 0.020000000000000018], [0.93, 0.06999999999999995]]\n375    0\n575    0\n313    1\n187    0\n429    0\n      ..\n436    1\n314    0\n98     0\n482    0\n382    0\nLength: 186, dtype: int64\nAccuracy against Hold Out set: 0.9139784946236559\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**K FOLD CROSS VALIDATION**\n\nWe will do the same as we just did, however will apply futher testing to see which model will preform the best overall not just on the given split","metadata":{}},{"cell_type":"code","source":"# Import k fold cross validation modules\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nk = 10  # Number of folds\nkfold = KFold(n_splits=k, shuffle=True)  # Create KFold object\n\n# Test gradient boosting model\nmodel = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", criterion=\"log_loss\")  \n\n# Define the log loss scorer\nlog_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True, labels=[0, 1, 2, 3])\nscores = cross_val_score(model, X, y, cv=kfold, scoring=log_loss_scorer)\nprint(\"Accuracy with Random Forests:\", scores.mean())","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:29.017161Z","iopub.execute_input":"2023-06-11T08:12:29.017523Z","iopub.status.idle":"2023-06-11T08:12:32.266767Z","shell.execute_reply.started":"2023-06-11T08:12:29.017491Z","shell.execute_reply":"2023-06-11T08:12:32.264881Z"},"trusted":true},"execution_count":304,"outputs":[{"name":"stdout","text":"Accuracy with Random Forests: -0.31123111912494483\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**PREDICT TEST DATA**\n\nWe will now predict the unknown test data with this model","metadata":{}},{"cell_type":"code","source":"# Construct the model\nmodel = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", criterion=\"log_loss\")  \nmodel.fit(X, y)\n\n# Import the data to predict\nX_test = pd.read_csv(DATA_PATH + \"test.csv\")\n\nids = X_test.loc[:, \"Id\"]\n# Do data processing\nX_test = process_data(X_test)\n\nprint(X_test.head())\n\n# predict results\ny_test_init = model.predict_proba(X_test)\ny_test_probs = conv_to_2_class(y_test_init)\nprint(y_test_probs)\n\nsubmissions = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n# We will change the Sample Submission value\nsubmissions[['class_0', 'class_1']] = y_test_probs\n\nsubmissions.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:12:32.268868Z","iopub.execute_input":"2023-06-11T08:12:32.269209Z","iopub.status.idle":"2023-06-11T08:12:32.686319Z","shell.execute_reply.started":"2023-06-11T08:12:32.269176Z","shell.execute_reply":"2023-06-11T08:12:32.685102Z"},"trusted":true},"execution_count":305,"outputs":[{"name":"stdout","text":"    AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD   ...   FI   FL   FR   FS  \\\n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n\n    GB   GE   GF   GH   GI   GL  \n0  0.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 56 columns]\n[[0.62, 0.38], [0.62, 0.38], [0.62, 0.38], [0.62, 0.38], [0.62, 0.38]]\n","output_type":"stream"}]}]}
